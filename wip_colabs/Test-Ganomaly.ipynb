{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Test-Ganomaly.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8h24gZHA22a",
        "outputId": "bfd42521-3fde-4400-f10a-1bd7463a8af6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ganomaly  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwF5Sv0UA22l",
        "outputId": "6cf8807b-4edb-493c-f3e5-6b3d3746b088",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/samet-akcay/ganomaly.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ganomaly' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlFEqc_2A22m",
        "outputId": "556430a7-3fcb-41ae-d20e-a462910fda5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r ganomaly/requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: asn1crypto==0.24.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 1)) (0.24.0)\n",
            "Requirement already satisfied: certifi==2019.6.16 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 2)) (2019.6.16)\n",
            "Requirement already satisfied: cffi==1.12.3 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 3)) (1.12.3)\n",
            "Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: cryptography==2.7 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 5)) (2.7)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: idna==2.8 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 7)) (2.8)\n",
            "Requirement already satisfied: joblib==0.13.2 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 8)) (0.13.2)\n",
            "Requirement already satisfied: kiwisolver==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: matplotlib==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 10)) (3.1.0)\n",
            "Collecting numpy==1.16.4\n",
            "  Using cached https://files.pythonhosted.org/packages/fc/d1/45be1144b03b6b1e24f9a924f23f66b4ad030d834ad31fb9e5581bd328af/numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile==0.46 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 12)) (0.46)\n",
            "Requirement already satisfied: Pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 13)) (8.1.0)\n",
            "Requirement already satisfied: pycparser==2.19 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 14)) (2.19)\n",
            "Requirement already satisfied: pyOpenSSL==19.0.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 15)) (19.0.0)\n",
            "Requirement already satisfied: pyparsing==2.4.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 16)) (2.4.0)\n",
            "Requirement already satisfied: PySocks==1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 17)) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil==2.8.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 18)) (2.8.0)\n",
            "Requirement already satisfied: pytz==2019.1 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 19)) (2019.1)\n",
            "Requirement already satisfied: pyzmq==18.0.2 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 20)) (18.0.2)\n",
            "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 21)) (2.22.0)\n",
            "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 22)) (0.21.2)\n",
            "Requirement already satisfied: scipy==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 23)) (1.3.0)\n",
            "Requirement already satisfied: six==1.12.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 24)) (1.12.0)\n",
            "Requirement already satisfied: torch==1.2.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 25)) (1.2.0)\n",
            "Requirement already satisfied: torchfile==0.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 26)) (0.1.0)\n",
            "Requirement already satisfied: torchvision==0.4 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 27)) (0.4.0)\n",
            "Requirement already satisfied: tornado==6.0.3 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 28)) (6.0.3)\n",
            "Requirement already satisfied: tqdm==4.33.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 29)) (4.33.0)\n",
            "Requirement already satisfied: urllib3==1.25.3 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 30)) (1.25.3)\n",
            "Requirement already satisfied: visdom==0.1.8.8 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 31)) (0.1.8.8)\n",
            "Requirement already satisfied: websocket-client==0.56.0 in /usr/local/lib/python3.7/dist-packages (from -r ganomaly/requirements.txt (line 32)) (0.56.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from kiwisolver==1.1.0->-r ganomaly/requirements.txt (line 9)) (53.0.0)\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement scikit-learn>=0.22, but you'll have scikit-learn 0.21.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mkl-fft 1.2.0 has requirement numpy==1.19.5, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.8.0 has requirement joblib>=0.14, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.16.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya7pv8pYA22n",
        "outputId": "caacaf74-bddc-4578-950e-9171388842bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "!pip install mkl-fft"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mkl-fft in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: dpcpp_cpp_rt in /usr/local/lib/python3.7/dist-packages (from mkl-fft) (2021.1.2)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-fft) (2019.0)\n",
            "Collecting numpy==1.19.5\n",
            "  Using cached https://files.pythonhosted.org/packages/08/d6/a6aaa29fea945bc6c61d11f6e0697b325ff7446de5ffd62c2fa02f627048/numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: common-cmplr-lic-rt==2021.* in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2021.1.2)\n",
            "Requirement already satisfied: common-cmplr-lib-rt==2021.* in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2021.1.2)\n",
            "Requirement already satisfied: opencl-rt==2021.* in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2021.1.2)\n",
            "Requirement already satisfied: intel-openmp==2021.* in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2021.1.2)\n",
            "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.7/dist-packages (from opencl-rt==2021.*->dpcpp_cpp_rt->mkl-fft) (2021.1.1)\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement scikit-learn>=0.22, but you'll have scikit-learn 0.21.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.8.0 has requirement joblib>=0.14, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "Successfully installed numpy-1.19.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uh8OFM3A22n"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6LIm61GA22o"
      },
      "source": [
        "# params\n",
        "OPT_isize = 32\n",
        "OPT_abnormal_class = \"plane\"\n",
        "OPT_manualseed = 55\n",
        "OPT_batchsize = 64\n",
        "OPT_workers = 8\n",
        "\n",
        "splits = ['train', 'test']\n",
        "drop_last_batch = {'train': True, 'test': False}\n",
        "shuffle = {'train': True, 'test': False}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KglesgFiA22o"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(OPT_isize),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")\n",
        "\n",
        "classes = {\n",
        "    'plane': 0, 'car': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
        "    'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHr6jnbHA22o",
        "outputId": "6f948683-f77a-4e04-c375-a6fa5b4fc98c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = {}\n",
        "dataset['train'] = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "dataset['test'] = CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZuEvH3BA22p"
      },
      "source": [
        "##\n",
        "def get_cifar_anomaly_dataset(trn_img, trn_lbl, tst_img, tst_lbl, abn_cls_idx=0, manualseed=-1):\n",
        "    \"\"\"[summary]\n",
        "    Arguments:\n",
        "        trn_img {np.array} -- Training images\n",
        "        trn_lbl {np.array} -- Training labels\n",
        "        tst_img {np.array} -- Test     images\n",
        "        tst_lbl {np.array} -- Test     labels\n",
        "    Keyword Arguments:\n",
        "        abn_cls_idx {int} -- Anomalous class index (default: {0})\n",
        "    Returns:\n",
        "        [np.array] -- New training-test images and labels.\n",
        "    \"\"\"\n",
        "    # Convert train-test labels into numpy array.\n",
        "    trn_lbl = np.array(trn_lbl)\n",
        "    tst_lbl = np.array(tst_lbl)\n",
        "    print(trn_lbl)\n",
        "\n",
        "    # --\n",
        "    # Find idx, img, lbl for abnormal and normal on org dataset.\n",
        "    nrm_trn_idx = np.where(trn_lbl != abn_cls_idx)[0]\n",
        "    abn_trn_idx = np.where(trn_lbl == abn_cls_idx)[0]\n",
        "    print(type(nrm_trn_idx))\n",
        "    print(nrm_trn_idx)\n",
        "    nrm_trn_img = trn_img[nrm_trn_idx]    # Normal training images\n",
        "    abn_trn_img = trn_img[abn_trn_idx]    # Abnormal training images\n",
        "    nrm_trn_lbl = trn_lbl[nrm_trn_idx]    # Normal training labels\n",
        "    abn_trn_lbl = trn_lbl[abn_trn_idx]    # Abnormal training labels.\n",
        "\n",
        "    nrm_tst_idx = np.where(tst_lbl != abn_cls_idx)[0]\n",
        "    abn_tst_idx = np.where(tst_lbl == abn_cls_idx)[0]\n",
        "    nrm_tst_img = tst_img[nrm_tst_idx]    # Normal training images\n",
        "    abn_tst_img = tst_img[abn_tst_idx]    # Abnormal training images.\n",
        "    nrm_tst_lbl = tst_lbl[nrm_tst_idx]    # Normal training labels\n",
        "    abn_tst_lbl = tst_lbl[abn_tst_idx]    # Abnormal training labels.\n",
        "\n",
        "    # --\n",
        "    # Assign labels to normal (0) and abnormals (1)\n",
        "    nrm_trn_lbl[:] = 0\n",
        "    nrm_tst_lbl[:] = 0\n",
        "    abn_trn_lbl[:] = 1\n",
        "    abn_tst_lbl[:] = 1\n",
        "\n",
        "    # --\n",
        "    if manualseed != -1:\n",
        "        # Random seed.\n",
        "        # Concatenate the original train and test sets.\n",
        "        nrm_img = np.concatenate((nrm_trn_img, nrm_tst_img), axis=0)\n",
        "        nrm_lbl = np.concatenate((nrm_trn_lbl, nrm_tst_lbl), axis=0)\n",
        "        abn_img = np.concatenate((abn_trn_img, abn_tst_img), axis=0)\n",
        "        abn_lbl = np.concatenate((abn_trn_lbl, abn_tst_lbl), axis=0)\n",
        "\n",
        "        # Split the normal data into the new train and tests.\n",
        "        idx = np.arange(len(nrm_lbl))\n",
        "        np.random.seed(manualseed)\n",
        "        np.random.shuffle(idx)\n",
        "\n",
        "        nrm_trn_len = int(len(idx) * 0.80)\n",
        "        nrm_trn_idx = idx[:nrm_trn_len]\n",
        "        nrm_tst_idx = idx[nrm_trn_len:]\n",
        "\n",
        "        nrm_trn_img = nrm_img[nrm_trn_idx]\n",
        "        nrm_trn_lbl = nrm_lbl[nrm_trn_idx]\n",
        "        nrm_tst_img = nrm_img[nrm_tst_idx]\n",
        "        nrm_tst_lbl = nrm_lbl[nrm_tst_idx]\n",
        "\n",
        "    # Create new anomaly dataset based on the following data structure:\n",
        "    # - anomaly dataset\n",
        "    #   . -> train\n",
        "    #        . -> normal\n",
        "    #   . -> test\n",
        "    #        . -> normal\n",
        "    #        . -> abnormal\n",
        "    new_trn_img = np.copy(nrm_trn_img)\n",
        "    new_trn_lbl = np.copy(nrm_trn_lbl)\n",
        "    new_tst_img = np.concatenate((nrm_tst_img, abn_trn_img, abn_tst_img), axis=0)\n",
        "    new_tst_lbl = np.concatenate((nrm_tst_lbl, abn_trn_lbl, abn_tst_lbl), axis=0)\n",
        "\n",
        "    return new_trn_img, new_trn_lbl, new_tst_img, new_tst_lbl"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhzA9P5YA22p",
        "outputId": "7a33e886-6469-4180-bec0-efcc0d8675b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data, train_targets, \\\n",
        "test_data, test_targets = get_cifar_anomaly_dataset(\n",
        "    trn_img=dataset['train'].data,\n",
        "    trn_lbl=dataset['train'].targets,\n",
        "    tst_img=dataset['test'].data,\n",
        "    tst_lbl=dataset['test'].targets,\n",
        "    abn_cls_idx=classes[OPT_abnormal_class],\n",
        "    manualseed=OPT_manualseed\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 9 9 ... 9 1 1]\n",
            "<class 'numpy.ndarray'>\n",
            "[    0     1     2 ... 49997 49998 49999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm3SD5p8A22p"
      },
      "source": [
        "dataloader = {x: torch.utils.data.DataLoader(dataset=dataset[x],\n",
        "                                             batch_size=OPT_batchsize,\n",
        "                                             shuffle=shuffle[x],\n",
        "                                             num_workers=int(OPT_workers),\n",
        "                                             drop_last=drop_last_batch[x],\n",
        "                                             worker_init_fn=(None if OPT_manualseed == -1\n",
        "                                             else lambda x: np.random.seed(OPT_manualseed)))\n",
        "              for x in splits}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXQJjqUGA22q",
        "outputId": "d93e469f-be54-4fa1-e189-0e2cb2b0f48e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(dataloader)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1P6y_iNA22q",
        "outputId": "b34970f5-6a31-4c7d-f092-feff9504b501",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataloader.keys()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'test'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJrLId7mA22q",
        "outputId": "05031e4f-bd87-40f0-99de-a0cc67da5877",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dir(dataloader['train'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_DataLoader__initialized',\n",
              " '_DataLoader__multiprocessing_context',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_auto_collation',\n",
              " '_index_sampler',\n",
              " 'batch_sampler',\n",
              " 'batch_size',\n",
              " 'collate_fn',\n",
              " 'dataset',\n",
              " 'dataset_kind',\n",
              " 'drop_last',\n",
              " 'multiprocessing_context',\n",
              " 'num_workers',\n",
              " 'pin_memory',\n",
              " 'sampler',\n",
              " 'timeout',\n",
              " 'worker_init_fn']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43S3o9KFA22r",
        "outputId": "eae991d9-d149-4f56-a206-3a614e9d527b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(type(dataloader))\n",
        "type(dataloader['train'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDUs7fexA22r"
      },
      "source": [
        "# iterate through and print few of the data types stored within the iterator to examine it\n",
        "# Create a similar iterator for the OASIS-3 no-ad scans directory"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B70vfqEZA22r"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}