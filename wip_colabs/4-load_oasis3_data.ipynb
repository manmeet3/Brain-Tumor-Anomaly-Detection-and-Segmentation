{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-load_oasis3_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvU5vMeB3tL8",
        "outputId": "0a50929e-9660-438c-88b1-703fbc9affd3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPD5t7AP35Ba",
        "outputId": "be89325a-c21c-4d63-ee45-b9ee3a63aaf8"
      },
      "source": [
        "%cd /content/drive/MyDrive/Masters_Project/Datasets/OASIS3/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1bqqm9-0FMOqiqyH_NIQBh-lJ36pWa7aX/Masters_Project/Datasets/OASIS3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZu16iC63UUK",
        "outputId": "7a5b60bb-2de8-482c-d2c7-5dfc15f370d7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " cifar-10-batches-py\t  fa20\t\t    t1w_non_ad_patients\n",
            " cifar-10-python.tar.gz   oasis-scripts    'Usage Instructions.gdoc'\n",
            " data\t\t\t  t1w_ad_jpgs\n",
            " downloaded_data\t  t1w_non_ad_jpgs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dXxoGdws3UUV",
        "outputId": "109f9a56-8893-4d56-8c3c-61d9746c0680"
      },
      "source": [
        "!pip install -r ../../Code/ganomaly/requirements.txt\r\n",
        "#!pip install -r ./ganomaly/requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: asn1crypto==0.24.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 1)) (0.24.0)\n",
            "Requirement already satisfied: certifi==2019.6.16 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 2)) (2019.6.16)\n",
            "Requirement already satisfied: cffi==1.12.3 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 3)) (1.12.3)\n",
            "Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: cryptography==2.7 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 5)) (2.7)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: idna==2.8 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 7)) (2.8)\n",
            "Requirement already satisfied: joblib==0.13.2 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 8)) (0.13.2)\n",
            "Requirement already satisfied: kiwisolver==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: matplotlib==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 10)) (3.1.0)\n",
            "Collecting numpy==1.16.4\n",
            "  Using cached https://files.pythonhosted.org/packages/fc/d1/45be1144b03b6b1e24f9a924f23f66b4ad030d834ad31fb9e5581bd328af/numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile==0.46 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 12)) (0.46)\n",
            "Requirement already satisfied: Pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 13)) (8.1.0)\n",
            "Requirement already satisfied: pycparser==2.19 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 14)) (2.19)\n",
            "Requirement already satisfied: pyOpenSSL==19.0.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 15)) (19.0.0)\n",
            "Requirement already satisfied: pyparsing==2.4.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 16)) (2.4.0)\n",
            "Requirement already satisfied: PySocks==1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 17)) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil==2.8.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 18)) (2.8.0)\n",
            "Requirement already satisfied: pytz==2019.1 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 19)) (2019.1)\n",
            "Requirement already satisfied: pyzmq==18.0.2 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 20)) (18.0.2)\n",
            "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 21)) (2.22.0)\n",
            "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 22)) (0.21.2)\n",
            "Requirement already satisfied: scipy==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 23)) (1.3.0)\n",
            "Requirement already satisfied: six==1.12.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 24)) (1.12.0)\n",
            "Requirement already satisfied: torch==1.2.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 25)) (1.2.0)\n",
            "Requirement already satisfied: torchfile==0.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 26)) (0.1.0)\n",
            "Requirement already satisfied: torchvision==0.4 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 27)) (0.4.0)\n",
            "Requirement already satisfied: tornado==6.0.3 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 28)) (6.0.3)\n",
            "Requirement already satisfied: tqdm==4.33.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 29)) (4.33.0)\n",
            "Requirement already satisfied: urllib3==1.25.3 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 30)) (1.25.3)\n",
            "Requirement already satisfied: visdom==0.1.8.8 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 31)) (0.1.8.8)\n",
            "Requirement already satisfied: websocket-client==0.56.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../Code/ganomaly/requirements.txt (line 32)) (0.56.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from kiwisolver==1.1.0->-r ../../Code/ganomaly/requirements.txt (line 9)) (53.0.0)\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement scikit-learn>=0.22, but you'll have scikit-learn 0.21.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mkl-fft 1.2.0 has requirement numpy==1.19.5, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.8.0 has requirement joblib>=0.14, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.16.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "LJXouR6y3UUW",
        "outputId": "12381cf4-a75b-485a-b8b1-c4a97f088d38"
      },
      "source": [
        "!pip install mkl-fft"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mkl-fft in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Collecting numpy==1.19.5\n",
            "  Using cached https://files.pythonhosted.org/packages/08/d6/a6aaa29fea945bc6c61d11f6e0697b325ff7446de5ffd62c2fa02f627048/numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: dpcpp_cpp_rt in /usr/local/lib/python3.7/dist-packages (from mkl-fft) (2021.1.2)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-fft) (2019.0)\n",
            "Requirement already satisfied: common-cmplr-lic-rt==2021.* in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2021.1.2)\n",
            "Requirement already satisfied: common-cmplr-lib-rt==2021.* in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2021.1.2)\n",
            "Requirement already satisfied: opencl-rt==2021.* in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2021.1.2)\n",
            "Requirement already satisfied: intel-openmp==2021.* in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2021.1.2)\n",
            "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.7/dist-packages (from opencl-rt==2021.*->dpcpp_cpp_rt->mkl-fft) (2021.1.1)\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement scikit-learn>=0.22, but you'll have scikit-learn 0.21.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.8.0 has requirement joblib>=0.14, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "Successfully installed numpy-1.19.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooHk9Hpm5aww",
        "outputId": "eb42e253-4643-4a00-c80b-ad929298b108"
      },
      "source": [
        "!pip install Pillow"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (8.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWYyHTRj9Pi6"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPv2uxvO3UUW"
      },
      "source": [
        "import os\n",
        "#import os.path\n",
        "#import cv2\n",
        "import glob\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "from typing import Any, Callable, Optional, Tuple\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import VisionDataset\n",
        "from torchvision.datasets.utils import check_integrity, download_and_extract_archive"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxCZS52C3UUW",
        "outputId": "652062cc-de40-4834-f604-0c376b5f7d34"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oJArWMRm3UUX",
        "outputId": "3b3befbf-71ba-4dd5-a6ec-1c069840dfc3"
      },
      "source": [
        "import torchvision\n",
        "torchvision.__version__"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTPtCs-A9RDh"
      },
      "source": [
        "# Create Oasis3 data class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXkVpUwV4Xnn"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5])# https://github.com/yunjey/pytorch-tutorial/issues/161\n",
        "        \n",
        "    ]\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNw2JbDA3UUY"
      },
      "source": [
        "train_image_number = 140 # Image slice from MRI scans to use for training data\n",
        "\n",
        "base_folder = '/pyt_oasis3'\n",
        "non_ad_jpg_folder = './t1w_non_ad_jpgs/' + str(train_image_number) + '/'\n",
        "ad_jpg_folder = './t1w_ad_jpgs/' + str(train_image_number) + '/'\n",
        "\n",
        "class Oasis3_train_normal(VisionDataset):\n",
        "    def __init__(self,\n",
        "            root: str,\n",
        "            train: bool = True, # Train or test dataset\n",
        "            transform: Optional[Callable] = None,\n",
        "            target_transform: Optional[Callable] = None) -> None:\n",
        "        super(Oasis3_train_normal, self).__init__(root, transform=transform, target_transform=target_transform)\n",
        "        self.train = train # Train or test set\n",
        "\n",
        "        # Set repeatble random number\n",
        "        \n",
        "        self.non_ad_data = []\n",
        "        self.non_ad_targets = []\n",
        "\n",
        "        self.ad_data = []\n",
        "        self.ad_targets = []\n",
        "        \n",
        "        # load both datasets\n",
        "        for file_path in glob.glob(ad_jpg_folder+'**.jpg'):\n",
        "            with open (file_path, 'rb') as f:\n",
        "                # image needs to be a PIL image\n",
        "                img = Image.open(f)\n",
        "                # Resize all images 176, 256, 3 -> 256, 256, 0\n",
        "                dsize = (256, 256)\n",
        "                resized = img.resize(dsize)\n",
        "                self.ad_data.append(resized)\n",
        "                self.ad_targets.extend(str(1)) # based on the jpg_folder in for loop\n",
        "        self.ad_data = np.vstack(self.ad_data).reshape(-1, 256, 256)\n",
        "        #self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
        "        self.ad_data = self.ad_data.transpose((0, 1, 2))  # convert to HWC\n",
        "\n",
        "        for file_path in glob.glob(non_ad_jpg_folder+'**.jpg'):\n",
        "            with open (file_path, 'rb') as f:\n",
        "                # image needs to be a PIL image\n",
        "                img = Image.open(f)\n",
        "                # Resize all images 176, 256, 3 -> 256, 256, 0\n",
        "                dsize = (256, 256)\n",
        "                resized = img.resize(dsize)\n",
        "                self.non_ad_data.append(resized)\n",
        "                self.non_ad_targets.extend(str(0)) # based on the jpg_folder in for loop\n",
        "        self.non_ad_data = np.vstack(self.non_ad_data).reshape(-1, 256, 256)\n",
        "        #self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
        "        self.non_ad_data = self.non_ad_data.transpose((0, 1, 2))  # convert to HWC\n",
        "        \n",
        "        # shuffle the datasets and bucket them as test and train\n",
        "        (self.non_ad_data, self.non_ad_targets) = self.shuffle_associated_arrays(self.non_ad_data, self.non_ad_targets)\n",
        "        (self.ad_data, self.ad_targets) = self.shuffle_associated_arrays(self.ad_data, self.ad_targets)\n",
        "\n",
        "        all_data = self.non_ad_data + self.ad_data\n",
        "        all_targets = self.non_ad_targets + self.ad_targets\n",
        "        # concat the lists and random shuffly\n",
        "        random.Random(1).shuffle(all_data)\n",
        "        random.Random(1).shuffle(all_targets)\n",
        "\n",
        "        # Use scikit learn to split complete data into test and train\n",
        "        self.train_data, self.test_data, self.train_targets, self.test_targets =\\\n",
        "         train_test_split(all_data, all_targets, test_size=0.1, random_state=42)\n",
        "\n",
        "        # Set test or train data based on input\n",
        "        if self.train:\n",
        "          self.data = self.train_data\n",
        "          self.targets = self.train_targets\n",
        "        else:\n",
        "          self.data = self.test_data\n",
        "          self.targets = self.test_targets\n",
        "\n",
        "    def shuffle_associated_arrays(self, arr1, arr2):\n",
        "        c = list(zip(arr1, arr2))\n",
        "        random.shuffle(c)\n",
        "        arr1, arr2 = zip(*c)\n",
        "        return (list(arr1), list(arr2))\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        \n",
        "        img = Image.fromarray(img)\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return (img, target)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t53epg7x3UUY"
      },
      "source": [
        "# Issue is i need to make the data transformable inside __getitem__\n",
        "a=Oasis3_train_normal(base_folder, False, transform=transform)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpqwrxpo3UUZ",
        "outputId": "a86c982d-b1b9-4107-e133-cafb5da04d44"
      },
      "source": [
        "# Shape : (256, 256)\n",
        "a.data[0].shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JzUbocMHkcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e1cf1c8-1514-4ef3-8bd2-fbf69cc122b5"
      },
      "source": [
        "# The class should be index into which invokes the __getitem__ call\n",
        "print(a[0][0])\n",
        "print(a[0][1])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.9843, -0.9608, -0.9608,  ..., -0.9765, -0.9765, -1.0000],\n",
            "         [-0.9686, -0.9608, -0.9843,  ..., -0.9608, -0.9686, -0.9922],\n",
            "         [-0.9529, -0.9686, -1.0000,  ..., -0.9529, -0.9686, -0.9922],\n",
            "         ...,\n",
            "         [-0.8980, -0.9294, -0.9608,  ..., -0.9765, -0.9765, -1.0000],\n",
            "         [-0.9137, -0.9373, -0.9608,  ..., -0.9686, -0.9765, -1.0000],\n",
            "         [-0.9451, -0.9529, -0.9608,  ..., -0.9529, -0.9765, -1.0000]]])\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}