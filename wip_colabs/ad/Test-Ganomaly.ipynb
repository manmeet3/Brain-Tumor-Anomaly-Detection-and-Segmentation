{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Test-Ganomaly.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwF5Sv0UA22l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19fd5025-4aad-48c1-91eb-c96dce7fea83"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r0sUHQffr9J",
        "outputId": "2cffd443-7ea8-4f9f-bacb-1dd0d041b34f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/drive/MyDrive/Masters_Project/Datasets/OASIS3/ganomaly_pytorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Masters_Project/Datasets/OASIS3/ganomaly_pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU5NG-3Zl2LS"
      },
      "source": [
        "# TODO\n",
        "Fix issue causing multiclass labels to be sent to evaluation class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlFEqc_2A22m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2fd28afd-39f4-4168-99ab-d183c52aff49"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting asn1crypto==0.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 6.5MB/s \n",
            "\u001b[?25hCollecting certifi==2019.6.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/1b/b853c7a9d4f6a6d00749e94eb6f3a041e342a885b87340b79c1ef73e3a78/certifi-2019.6.16-py2.py3-none-any.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 13.2MB/s \n",
            "\u001b[?25hCollecting cffi==1.12.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/ea/37fe21475c884f88a2ae496cab10e8f84f0cc11137be860af9eb37a3edb9/cffi-1.12.3-cp37-cp37m-manylinux1_x86_64.whl (430kB)\n",
            "\u001b[K     |████████████████████████████████| 440kB 21.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.0.4)\n",
            "Collecting cryptography==2.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/18/c6557f63a6abde34707196fb2cad1c6dc0dbff25a200d5044922496668a4/cryptography-2.7-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.10.0)\n",
            "Collecting idna==2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
            "\u001b[?25hCollecting joblib==0.13.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 43.6MB/s \n",
            "\u001b[?25hCollecting kiwisolver==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/f8/518fb0bb89860eea6ff1b96483fbd9236d5ee991485d0f3eceff1770f654/kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.2MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/cb/a34046e75c9a4ecaf426ae0d0eada97078c8ce4bbe3250940b1a312a1385/matplotlib-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (13.1MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1MB 25.7MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/d1/45be1144b03b6b1e24f9a924f23f66b4ad030d834ad31fb9e5581bd328af/numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 302kB/s \n",
            "\u001b[?25hCollecting olefile==0.46\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/81/e1ac43c6b45b4c5f8d9352396a14144bba52c8fec72a80f425f6a4d653ad/olefile-0.46.zip (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 55.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (7.1.2)\n",
            "Collecting pycparser==2.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 49.5MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL==19.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/c8/ceb170d81bd3941cbeb9940fc6cc2ef2ca4288d0ca8929ea4db5905d904d/pyOpenSSL-19.0.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d9/3ec19e966301a6e25769976999bd7bbe552016f0d32b577dc9d63d2e0c49/pyparsing-2.4.0-py2.py3-none-any.whl (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n",
            "\u001b[?25hCollecting PySocks==1.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/18/102cc70347486e75235a29a6543f002cf758042189cb063ec25334993e36/PySocks-1.7.0-py3-none-any.whl\n",
            "Collecting python-dateutil==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 57.5MB/s \n",
            "\u001b[?25hCollecting pytz==2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 45.3MB/s \n",
            "\u001b[?25hCollecting pyzmq==18.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/43/ac5473e08294fd1fc512e54c39b702de1c848391f9b2d073279f5dc7a986/pyzmq-18.0.2-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 51.2MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/a4/a48bd4b0d15395362b561df7e7247de87291105eb736a3b2aaffebf437b9/scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 41.1MB/s \n",
            "\u001b[?25hCollecting scipy==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/bd/c0feba81fb60e231cf40fc8a322ed5873c90ef7711795508692b1481a4ae/scipy-1.3.0-cp37-cp37m-manylinux1_x86_64.whl (25.2MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2MB 1.6MB/s \n",
            "\u001b[?25hCollecting six==1.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Collecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/65/5248be50c55ab7429dd5c11f5e2f9f5865606b80e854ca63139ad1a584f2/torch-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (748.9MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 24kB/s \n",
            "\u001b[?25hCollecting torchfile==0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting torchvision==0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/83/2d77d040e34bd8f70dcb4770f7eb7d0aa71e07738abf6831be863ade00db/torchvision-0.4.0-cp37-cp37m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 27.7MB/s \n",
            "\u001b[?25hCollecting tornado==6.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/78/2d2823598496127b21423baffaa186b668f73cd91887fcef78b6eade136b/tornado-6.0.3.tar.gz (482kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 50.7MB/s \n",
            "\u001b[?25hCollecting tqdm==4.33.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/56/60a5b1c2e634d8e4ff89c7bab47645604e19658f448050a21facffd43796/tqdm-4.33.0-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[?25hCollecting urllib3==1.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/60/247f23a7121ae632d62811ba7f273d0e58972d75e58a94d329d51550a47d/urllib3-1.25.3-py2.py3-none-any.whl (150kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 61.4MB/s \n",
            "\u001b[?25hCollecting visdom==0.1.8.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/c4/5f5356fd57ae3c269e0e31601ea6487e0622fedc6756a591e4a5fd66cc7a/visdom-0.1.8.8.tar.gz (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 50.3MB/s \n",
            "\u001b[?25hCollecting websocket-client==0.56.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 48.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from kiwisolver==1.1.0->-r requirements.txt (line 9)) (54.2.0)\n",
            "Building wheels for collected packages: olefile, pycparser, torchfile, tornado, visdom\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35416 sha256=09ddba49b3ec4fe0167e4ef2840107c52f67d29d8c5b388145fc238d2efa35a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/f4/11/bc4166107c27f07fd7bba707ffcb439619197638a1ac986df3\n",
            "  Building wheel for pycparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycparser: filename=pycparser-2.19-py2.py3-none-any.whl size=111031 sha256=42d32d164dd08247811e9212432ddf8e9ab44b5027729c0dbe833dc82352e6ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/9a/90/de94f8556265ddc9d9c8b271b0f63e57b26fb1d67a45564511\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp37-none-any.whl size=5713 sha256=d74b69f4ae0bc6ab567ba52be9c7bde66dbe5ff55699eea7b7c18bbf8f56099e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-6.0.3-cp37-cp37m-linux_x86_64.whl size=424123 sha256=132f3c49826a67e43c08177c02188bcd16224413b8c219ce55e45fb318932288\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/bf/40/2f6ef700f48401ca40e5e3dd7d0e3c0a90e064897b7fe5fc08\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.8-cp37-none-any.whl size=1350604 sha256=1309bfa354c02f323193ad7bb0dc6add96c0b435d9c80d41202bad46379a0dcb\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/87/ce/a5023722374ca73b57fc8d4284ba6f973c01219b3c385a07e0\n",
            "Successfully built olefile pycparser torchfile tornado visdom\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 3.0.0 has requirement numpy>=1.16.6, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.8.0 has requirement joblib>=0.14, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-python-client 1.12.8 has requirement six<2dev,>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-core 1.26.2 has requirement six>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.33.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.2 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: asn1crypto, certifi, pycparser, cffi, six, cryptography, idna, joblib, kiwisolver, pyparsing, numpy, python-dateutil, matplotlib, olefile, pyOpenSSL, PySocks, pytz, pyzmq, urllib3, requests, scipy, scikit-learn, torch, torchfile, torchvision, tornado, tqdm, websocket-client, visdom\n",
            "  Found existing installation: certifi 2020.12.5\n",
            "    Uninstalling certifi-2020.12.5:\n",
            "      Successfully uninstalled certifi-2020.12.5\n",
            "  Found existing installation: pycparser 2.20\n",
            "    Uninstalling pycparser-2.20:\n",
            "      Successfully uninstalled pycparser-2.20\n",
            "  Found existing installation: cffi 1.14.5\n",
            "    Uninstalling cffi-1.14.5:\n",
            "      Successfully uninstalled cffi-1.14.5\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: joblib 1.0.1\n",
            "    Uninstalling joblib-1.0.1:\n",
            "      Successfully uninstalled joblib-1.0.1\n",
            "  Found existing installation: kiwisolver 1.3.1\n",
            "    Uninstalling kiwisolver-1.3.1:\n",
            "      Successfully uninstalled kiwisolver-1.3.1\n",
            "  Found existing installation: pyparsing 2.4.7\n",
            "    Uninstalling pyparsing-2.4.7:\n",
            "      Successfully uninstalled pyparsing-2.4.7\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: PySocks 1.7.1\n",
            "    Uninstalling PySocks-1.7.1:\n",
            "      Successfully uninstalled PySocks-1.7.1\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pyzmq 22.0.3\n",
            "    Uninstalling pyzmq-22.0.3:\n",
            "      Successfully uninstalled pyzmq-22.0.3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "  Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed PySocks-1.7.0 asn1crypto-0.24.0 certifi-2019.6.16 cffi-1.12.3 cryptography-2.7 idna-2.8 joblib-0.13.2 kiwisolver-1.1.0 matplotlib-3.1.0 numpy-1.16.4 olefile-0.46 pyOpenSSL-19.0.0 pycparser-2.19 pyparsing-2.4.0 python-dateutil-2.8.0 pytz-2019.1 pyzmq-18.0.2 requests-2.22.0 scikit-learn-0.21.2 scipy-1.3.0 six-1.12.0 torch-1.2.0 torchfile-0.1.0 torchvision-0.4.0 tornado-6.0.3 tqdm-4.33.0 urllib3-1.25.3 visdom-0.1.8.8 websocket-client-0.56.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cffi",
                  "dateutil",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pyparsing",
                  "pytz",
                  "six",
                  "tornado",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya7pv8pYA22n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43df8baa-e405-4f6b-dd94-3491bf2acb5f"
      },
      "source": [
        "!pip install mkl-fft"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mkl-fft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/3e/fdc76badb389a446ab28df79f243989ec3b5219c033a55d5ac37eda3ce32/mkl_fft-1.3.0-1-cp37-cp37m-manylinux2014_x86_64.whl (240kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 15.0MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 184kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-fft) (2019.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from mkl-fft) (1.16.4)\n",
            "Collecting dpcpp_cpp_rt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/b3/dfeee3ca5e9a04a3f4051583c2ec94fe4f2e2c09904e4e16b41ff100c212/dpcpp_cpp_rt-2021.2.0-py2.py3-none-manylinux1_x86_64.whl (171.6MB)\n",
            "\u001b[K     |████████████████████████████████| 171.6MB 85kB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->mkl-fft) (2021.2.0)\n",
            "Collecting common-cmplr-lib-rt==2021.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/d3/ac47da09e4e0b94945a6338379a513d8486c2cf078b5c3f60a5401bd47e0/common_cmplr_lib_rt-2021.2.0-py2.py3-none-manylinux1_x86_64.whl (31.6MB)\n",
            "\u001b[K     |████████████████████████████████| 31.6MB 175kB/s \n",
            "\u001b[?25hCollecting common-cmplr-lic-rt==2021.*\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/66/5bf5cd09702d949a65c3fe7e5a4f63dec7fa48c77ddb5b11ba391ecbae38/common_cmplr_lic_rt-2021.2.0-py2.py3-none-manylinux1_x86_64.whl\n",
            "Collecting opencl-rt==2021.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/0e/c8a2e4c3b3217368af845910bd699e93b0a85564cdb378c15ed97ac2cc5d/opencl_rt-2021.2.0-py2.py3-none-manylinux1_x86_64.whl (169.0MB)\n",
            "\u001b[K     |████████████████████████████████| 169.0MB 102kB/s \n",
            "\u001b[?25hCollecting tbb==2021.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/55/bd1f776ede9b86b918e390119461281fcb8a86e1918f0da467dc5aece4a2/tbb-2021.2.0-py2.py3-none-manylinux1_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 48.7MB/s \n",
            "\u001b[?25hInstalling collected packages: common-cmplr-lib-rt, common-cmplr-lic-rt, tbb, opencl-rt, dpcpp-cpp-rt, mkl-fft\n",
            "Successfully installed common-cmplr-lib-rt-2021.2.0 common-cmplr-lic-rt-2021.2.0 dpcpp-cpp-rt-2021.2.0 mkl-fft-1.3.0 opencl-rt-2021.2.0 tbb-2021.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiBYORYdsR1U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "1a09a84d-7b3e-42ae-949d-883b7bd84150"
      },
      "source": [
        "#!pip install Pillow==6.2.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==6.2.2\n",
            "  Using cached https://files.pythonhosted.org/packages/c3/3f/03375124676ab49ca6e6917c0f1f663afb8354d5d24e12f4fe4587a39ae2/Pillow-6.2.2-cp37-cp37m-manylinux1_x86_64.whl\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 8.1.0\n",
            "    Uninstalling Pillow-8.1.0:\n",
            "      Successfully uninstalled Pillow-8.1.0\n",
            "Successfully installed Pillow-6.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uh8OFM3A22n"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from options import Options\n",
        "from lib.data import load_data\n",
        "from lib.model import Ganomaly"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6LIm61GA22o"
      },
      "source": [
        "# params\n",
        "OPT_isize = 32\n",
        "OPT_abnormal_class = \"plane\"\n",
        "OPT_manualseed = 55\n",
        "OPT_batchsize = 64\n",
        "OPT_workers = 8\n",
        "\n",
        "splits = ['train', 'test']\n",
        "drop_last_batch = {'train': True, 'test': False}\n",
        "shuffle = {'train': True, 'test': False}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KglesgFiA22o"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(OPT_isize),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")\n",
        "\n",
        "classes = {\n",
        "    'plane': 0, 'car': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
        "    'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHr6jnbHA22o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b76c13b-6a4d-4442-e2e3-4116681677fa"
      },
      "source": [
        "dataset = {}\n",
        "dataset['train'] = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "dataset['test'] = CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:03, 43407655.74it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5ezcZtpze34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621ba390-fd69-4ee1-981c-414e00879c80"
      },
      "source": [
        "type(dataset['train'].targets)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZuEvH3BA22p"
      },
      "source": [
        "##\n",
        "def get_cifar_anomaly_dataset(trn_img, trn_lbl, tst_img, tst_lbl, abn_cls_idx=0, manualseed=-1):\n",
        "    \"\"\"[summary]\n",
        "    Arguments:\n",
        "        trn_img {np.array} -- Training images\n",
        "        trn_lbl {np.array} -- Training labels\n",
        "        tst_img {np.array} -- Test     images\n",
        "        tst_lbl {np.array} -- Test     labels\n",
        "    Keyword Arguments:\n",
        "        abn_cls_idx {int} -- Anomalous class index (default: {0})\n",
        "    Returns:\n",
        "        [np.array] -- New training-test images and labels.\n",
        "    \"\"\"\n",
        "    # Convert train-test labels into numpy array.\n",
        "    trn_lbl = np.array(trn_lbl)\n",
        "    tst_lbl = np.array(tst_lbl)\n",
        "    print(trn_lbl)\n",
        "\n",
        "    # --\n",
        "    # Find idx, img, lbl for abnormal and normal on org dataset.\n",
        "    nrm_trn_idx = np.where(trn_lbl != abn_cls_idx)[0]\n",
        "    abn_trn_idx = np.where(trn_lbl == abn_cls_idx)[0]\n",
        "    print(type(nrm_trn_idx))\n",
        "    print(nrm_trn_idx)\n",
        "    nrm_trn_img = trn_img[nrm_trn_idx]    # Normal training images\n",
        "    abn_trn_img = trn_img[abn_trn_idx]    # Abnormal training images\n",
        "    nrm_trn_lbl = trn_lbl[nrm_trn_idx]    # Normal training labels\n",
        "    abn_trn_lbl = trn_lbl[abn_trn_idx]    # Abnormal training labels.\n",
        "\n",
        "    nrm_tst_idx = np.where(tst_lbl != abn_cls_idx)[0]\n",
        "    abn_tst_idx = np.where(tst_lbl == abn_cls_idx)[0]\n",
        "    nrm_tst_img = tst_img[nrm_tst_idx]    # Normal training images\n",
        "    abn_tst_img = tst_img[abn_tst_idx]    # Abnormal training images.\n",
        "    nrm_tst_lbl = tst_lbl[nrm_tst_idx]    # Normal training labels\n",
        "    abn_tst_lbl = tst_lbl[abn_tst_idx]    # Abnormal training labels.\n",
        "\n",
        "    # --\n",
        "    # Assign labels to normal (0) and abnormals (1)\n",
        "    nrm_trn_lbl[:] = 0\n",
        "    nrm_tst_lbl[:] = 0\n",
        "    abn_trn_lbl[:] = 1\n",
        "    abn_tst_lbl[:] = 1\n",
        "\n",
        "    # --\n",
        "    if manualseed != -1:\n",
        "        # Random seed.\n",
        "        # Concatenate the original train and test sets.\n",
        "        nrm_img = np.concatenate((nrm_trn_img, nrm_tst_img), axis=0)\n",
        "        nrm_lbl = np.concatenate((nrm_trn_lbl, nrm_tst_lbl), axis=0)\n",
        "        abn_img = np.concatenate((abn_trn_img, abn_tst_img), axis=0)\n",
        "        abn_lbl = np.concatenate((abn_trn_lbl, abn_tst_lbl), axis=0)\n",
        "\n",
        "        # Split the normal data into the new train and tests.\n",
        "        idx = np.arange(len(nrm_lbl))\n",
        "        np.random.seed(manualseed)\n",
        "        np.random.shuffle(idx)\n",
        "\n",
        "        nrm_trn_len = int(len(idx) * 0.80)\n",
        "        nrm_trn_idx = idx[:nrm_trn_len]\n",
        "        nrm_tst_idx = idx[nrm_trn_len:]\n",
        "\n",
        "        nrm_trn_img = nrm_img[nrm_trn_idx]\n",
        "        nrm_trn_lbl = nrm_lbl[nrm_trn_idx]\n",
        "        nrm_tst_img = nrm_img[nrm_tst_idx]\n",
        "        nrm_tst_lbl = nrm_lbl[nrm_tst_idx]\n",
        "\n",
        "    # Create new anomaly dataset based on the following data structure:\n",
        "    # - anomaly dataset\n",
        "    #   . -> train\n",
        "    #        . -> normal\n",
        "    #   . -> test\n",
        "    #        . -> normal\n",
        "    #        . -> abnormal\n",
        "    new_trn_img = np.copy(nrm_trn_img)\n",
        "    new_trn_lbl = np.copy(nrm_trn_lbl)\n",
        "    new_tst_img = np.concatenate((nrm_tst_img, abn_trn_img, abn_tst_img), axis=0)\n",
        "    new_tst_lbl = np.concatenate((nrm_tst_lbl, abn_trn_lbl, abn_tst_lbl), axis=0)\n",
        "\n",
        "    return new_trn_img, new_trn_lbl, new_tst_img, new_tst_lbl"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhzA9P5YA22p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede0ac76-bc55-4ec4-c264-d157f13dd990"
      },
      "source": [
        "train_data, train_targets, \\\n",
        "test_data, test_targets = get_cifar_anomaly_dataset(\n",
        "    trn_img=dataset['train'].data,\n",
        "    trn_lbl=dataset['train'].targets,\n",
        "    tst_img=dataset['test'].data,\n",
        "    tst_lbl=dataset['test'].targets,\n",
        "    abn_cls_idx=classes[OPT_abnormal_class],\n",
        "    manualseed=OPT_manualseed\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 9 9 ... 9 1 1]\n",
            "<class 'numpy.ndarray'>\n",
            "[    0     1     2 ... 49997 49998 49999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm3SD5p8A22p"
      },
      "source": [
        "dataloader = {x: torch.utils.data.DataLoader(dataset=dataset[x],\n",
        "                                             batch_size=OPT_batchsize,\n",
        "                                             shuffle=shuffle[x],\n",
        "                                             num_workers=int(OPT_workers),\n",
        "                                             drop_last=drop_last_batch[x],\n",
        "                                             worker_init_fn=(None if OPT_manualseed == -1\n",
        "                                             else lambda x: np.random.seed(OPT_manualseed)))\n",
        "              for x in splits}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXQJjqUGA22q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf82222f-7c43-4fb1-fce0-69f3185f7711"
      },
      "source": [
        "type(dataloader)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1P6y_iNA22q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6e9a15-c0ba-40c3-c322-ca176dee54ab"
      },
      "source": [
        "dataloader.keys()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'test'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJrLId7mA22q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c18ec6-807e-49c3-b3c3-eaeafb5f721d"
      },
      "source": [
        "dir(dataloader['train'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_DataLoader__initialized',\n",
              " '_DataLoader__multiprocessing_context',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_auto_collation',\n",
              " '_index_sampler',\n",
              " 'batch_sampler',\n",
              " 'batch_size',\n",
              " 'collate_fn',\n",
              " 'dataset',\n",
              " 'dataset_kind',\n",
              " 'drop_last',\n",
              " 'multiprocessing_context',\n",
              " 'num_workers',\n",
              " 'pin_memory',\n",
              " 'sampler',\n",
              " 'timeout',\n",
              " 'worker_init_fn']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43S3o9KFA22r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109c8026-5b6d-40c0-8f9f-e3a01e7505e7"
      },
      "source": [
        "print(type(dataloader))\n",
        "type(dataloader['train'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDUs7fexA22r"
      },
      "source": [
        "# iterate through and print few of the data types stored within the iterator to examine it\n",
        "# Create a similar iterator for the OASIS-3 no-ad scans directory"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B70vfqEZA22r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b2f5b9-3e36-432d-a0ff-1b8c9d21f840"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t     lib\t options.pyc  README.md\n",
            "experiments  LICENSE\t output       requirements.txt\n",
            "__init__.py  options.py  __pycache__  train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuwZ1_gEa8tN"
      },
      "source": [
        "class Option:\n",
        "    def __init__(self):\n",
        "        # Base\n",
        "        self.dataset = 'cifar10'\n",
        "        self.dataroot = ''\n",
        "        self.batchsize = 64\n",
        "        self.workers = 8\n",
        "        self.droplast = True\n",
        "        self.isize = 32\n",
        "        self.nc = 3\n",
        "        self.nz = 100\n",
        "        self.ngf = 64\n",
        "        self.ndf = 64\n",
        "        self.extralayers = 0\n",
        "        self.device = 'gpu'\n",
        "        self.gpu_ids = '0'\n",
        "        self.ngpu = 1\n",
        "        self.name = 'pytorch_ganomaly'\n",
        "        self.model = 'ganomaly'\n",
        "        self.display_server = \"http://localhost\"\n",
        "        self.display_port = 8097\n",
        "        self.display_id = 0\n",
        "        self.display = False\n",
        "        self.outf = './pyt_ganomaly_output'\n",
        "        self.manualseed = -1\n",
        "        self.abnormal_class = 'car'\n",
        "        self.proportion = 0.1\n",
        "        self.metric = 'auprc' #roc\n",
        "\n",
        "        ##\n",
        "        # Train\n",
        "        self.print_freq = 100\n",
        "        self.save_image_freq = 100\n",
        "        self.save_test_images = True\n",
        "        self.load_weights = False\n",
        "        self.resume = ''\n",
        "        self.phase = 'train'\n",
        "        self.iter = 0\n",
        "        self.niter = 15\n",
        "        self.beta1 = 0.5\n",
        "        self.lr = 0.0002\n",
        "        self.w_adv = 1\n",
        "        self.w_con = 50\n",
        "        self.w_enc = 1\n",
        "        self.isTrain = True\n",
        "\n",
        "opt = Option()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhGpWshVa_ND",
        "outputId": "8afb2cf3-a9fd-41b9-9cd5-e7834d64fd81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "model = Ganomaly(opt, dataloader)\n",
        "model.train()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/781 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Training model Ganomaly.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "                                                 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Training model Ganomaly. Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-66d60090256c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGanomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/MyDrive/Masters_Project/Datasets/OASIS3/ganomaly_pytorch/lib/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# Train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_auc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mbest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Masters_Project/Datasets/OASIS3/ganomaly_pytorch/lib/model.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0man_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0man_scores\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0man_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0man_scores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0man_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;31m# auc, eer = roc(self.gt_labels, self.an_scores)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0man_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Avg Run Time (ms/batch)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Masters_Project/Datasets/OASIS3/ganomaly_pytorch/lib/evaluate.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(labels, scores, metric)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mroc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auprc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mauprc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'f1_score'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Masters_Project/Datasets/OASIS3/ganomaly_pytorch/lib/evaluate.py\u001b[0m in \u001b[0;36mauprc\u001b[0;34m(labels, scores)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mauprc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    238\u001b[0m                                 pos_label=pos_label)\n\u001b[1;32m    239\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[0;32m--> 240\u001b[0;31m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
          ]
        }
      ]
    }
  ]
}